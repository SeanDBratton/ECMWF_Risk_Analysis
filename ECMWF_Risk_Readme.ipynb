{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README: Statistical and Time Series Analysis of ECMWF Model Data ##\n",
    "\n",
    "### This script downloads all 50 members ECMWF ensemble members and identifies risk associated with each forecast period (6-hour intervals). Data visualizations including time series charts, climatology comparision charts, box and whisker plot, PDFs, and risk tables are also used to help visualize risk. Maps are also generated to show the evolution of the specified variable over a specific time period. ### \n",
    "\n",
    "### Data Sources ###\n",
    "\n",
    "#### 1) ECMWF: Ensemble ECMWF data is downloaded using a specific ECMWF python package. This library allows for the download of gridded EC data. It implements a request-based interface to the dataset using ECMWF's MARS language to select meteorological fields. The fields utilized as part of this project include surface wind (u and v components), surface temperature, mean sea-level pressure (MSLP), 500mb heights, and precipitation (was only able to get total column water vapor as a proxy). This data is downloaded in 6-hour intervals (this can be changed by the user) to provide a point forecast over one of the 21 locations using a 0.5 x 0.5 degree spatial resolution grid. Units for the downloaded data are set as part of this script ####\n",
    "\n",
    "#### The following conditions are used in downloading ECMWF data: ####\n",
    "* 0.5 x 0.5 grid resolution\n",
    "* 50 ensemble members\n",
    "* 6-hourly temporal resolution\n",
    "* can download data for 5 different atmos variables\n",
    " \n",
    "#### 2) Meteostat: 10 and 30 year climatologies are calculated using the Meteostat Python package. Nearest station approximator is used to find observational stations closest to specific lat/lon locations. Meteostat provides surface wind, temperature, pressure, and precipitation metrics down to hourly resolution. For this project, quantities will be averaged daily. ####\n",
    "\n",
    "### Data Analysis Techniques ###\n",
    " \n",
    "### Since this is not a classic research project, and instead a tool to help evaluate forecast risk, I will instead provide a justification for the various visuals provided in this project. I will also use an example using a recent model run for surface temperature, using Boston as the location of interest. ###\n",
    " \n",
    " \n",
    "#### *1) Distribution Chart* ####\n",
    "##### These charts are used to determine the spread among ensemble members over each forecast period. This helps to visually communicate times in the forecast period that have inherently more risk due to model divergence. The ensemble mean and median are provided to show these values for comparison among the individual members. The 10/30-year climo values are also provided as a reference to determine where mean and median values land relative to normal. #####\n",
    " \n",
    "#### *2) Climatology Comparisons* ####\n",
    "##### This plot digs a bit deeper into the comparison between the ensemble mean and climo. In this chart, the ensemble mean is compared to the 30-year climo over this location producing a positive or negative anomaly. Additionally, to help provide context on the magnitude of the anomaly, a +1 and -1 STDEV line is also provided to identify the +/- 1 STDEV for each time interval in the series for comparison. #####\n",
    " \n",
    "##### Note: It is important to consider that although the closest Meteostat station to the identified grid point is attempted, these two locations will not be exact. As a result, the accuracy may be compromised due to micro climatological/mesoscale features inherent to the location that can skew the climatological comparison. #####\n",
    " \n",
    "#### *3) Box and Whisker Plots* ####\n",
    "##### Box and whisker plots are provided for each forecast interval. This allows the user to better identify the variance inherent for each period, and the associated upper/lower quartile ranges. It also allows the user to determine if there are any outliers to consider indicating potential extreme values relative to the sample median. #####\n",
    " \n",
    "#### *4) Probability Distribution Tables* ####\n",
    "##### The probability table allows users to identify threshold limits and determine the likelihood based on model distribution that these these thresholds are met. To determine these probabilities, a z-score is run based on the model mean and the user input threshold. This z-score is then compared to a normal distribution of values to determine how likely it is that this threshold is met. This works for \"greater than\" or \"less than\" conditions. These probabilities are also color coded to help visually identify time periods of risk. Probabilites 60-80% are yellow, >80% are red. #####\n",
    "  \n",
    "#### *5) Model Variance/Spread Metrics* ####\n",
    "##### This table quantifies the variance within the model. The following quantities are identified as part of this model: ensemble mean, ensemble variance, 10th percentile, 90th percentile, ensemble variance, ensemble percentile spread. The 10th and 90th percentile are used to categorize the extreme ends (high/low) of the spectrum. The variance, or standard deviation, of a dataset provides a metric to describe the spread of the data relative to the mean. This standard deviation metric and percentile spread score (difference between 10 and 90th percentile) should be significantly correlated. #####\n",
    " \n",
    "#### *6) Spatial Maps of Weather Variable including Animations* ####\n",
    " \n",
    "##### There are two versions of the mapping plots. These plots produce a 4x4 lat/lon grid for the variable identified by the user. The station location is also identified for reference. For the first set of still image maps, the user selects the time frames and range to display (all 50 time frames are too many to plot as output). PlateCarree projection is used for the plots using the cartopy contourf functionality. #####\n",
    " \n",
    "##### The second version of these plots is an animated series of images. This is used to accommodate the large number of output maps that correspond to each time frame. The matplotlib animation library is used to complete this series of animated images. The same cartopy input as the still images are used #####\n",
    "\n",
    "#### *7) Histogram with PDF* ####\n",
    "##### A histogram of model output for each model member is provided as part of the histogram along with a probability density function. This is used to better understand the distribution of values for the identified period. An ensemble mean, median and the 10th/90th percentiles are used for reference as part of this plot. This is helpful in determining if the verification value is higher or lower than the ensemble mean based on the shape of the distribution. This is also helpful to better identify potential outlier or extreme events. #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
